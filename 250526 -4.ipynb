{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d83bc56",
   "metadata": {},
   "source": [
    "LangChainMemory\n",
    "```\n",
    "LangChainMemory : 이전 대화 내용을 기억해서 문맥을 유지하는 역할 LangChain 0.3X부터는 LCEL 기반으로 체인을 구성,\n",
    "RunnableWithMessageHistoru, ChatMessageHistory 등의 컴퍼넌트를 활용해서 세션별 대화 기록을 관리, 대화가 장기화될 경우 요약 메모리를 도입해서 과거 대화를 LLM으로 요약하고 축약된 형태로 저장해서 프롬프트의 길이 문제를 해결결\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c355362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3040fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4647d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human : 언녕하세요 제 이름은 이주영영입니다.\n",
      "ai : 안녕하세요 이주영님, 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "# 메모리 객체 생성\n",
    "history = InMemoryChatMessageHistory()\n",
    "history.add_user_message('언녕하세요 제 이름은 이주영영입니다.')\n",
    "history.add_ai_message('안녕하세요 이주영님, 무엇을 도와드릴까요?')\n",
    "# 현재까지의 대화 내용 확인\n",
    "for msg in history.messages:\n",
    "    print(f'{msg.type} : {msg.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c933f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_redis'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Radis 기반 채팅 기록 저장소\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_redis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RedisChatMessageHistory\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m REDIS_URL = os.getenv(\u001b[33m'\u001b[39m\u001b[33mREDIS_URL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mredis://localhost:6379\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_redis'"
     ]
    }
   ],
   "source": [
    "# Radis 기반 채팅 기록 저장소\n",
    "\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "import os\n",
    "REDIS_URL = os.getenv('REDIS_URL', 'redis://localhost:6379')\n",
    "session_id = 'user_123'\n",
    "\n",
    "history = RedisChatMessageHistory(session_id = session_id, redis_url = REDIS_URL)\n",
    "history.add_user_message('안녕하세요 제 이름은 홍길동 입니다.')\n",
    "history.add_ai_message('안녕하세요 홍길동님, 무엇을 도와드릴까요?')\n",
    "\n",
    "# 현재까지의 대화 내용 확인\n",
    "for msg in history.messages:\n",
    "    print(f'{msg.type} : {msg.content}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6b303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션기반 다중사용자 메모리 구조 구현 - 다중사용자 챗복\n",
    "# 핵심: session_id를 키로 하는 메모리 저장소 만들고 사용자의 대화는 키별로 저장한다\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",'당신은 뛰어난 한국어 상담 챗봇입니다. 질문에 친절하고 자세히 답변해주세요'),\n",
    "    #history 키로 전달된 메세지 목록은 chain 실행시 해당 위치에 넣겠다는 의미\n",
    "    MessagesPlaceholder(variable_name='history'), \n",
    "    ('human','{input}')\n",
    "])\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322df069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3694e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션별 메모리 저장소를 딕셔너리로 만들고, 존재하지 않는 새로운 세션 id가 들어오면 InMemoryChatMessageHistory를 생성\n",
    "# get_sessino_history 를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea5995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "#세션 id -> 대화 기록 객체 매핑\n",
    "store = {}\n",
    "def get_session_history(session_id : str) -> InMemoryChatMessageHistory:\n",
    "    '''\"세션 ID\"에 해당하는 대화 기록 객체를 반환합니다. (없으면 새로 생성)'''\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 메모리를 통합한 체인 래퍼생성\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    runnable = chain,\n",
    "    get_session_history = get_session_history,\n",
    "    input_messages_key= 'input',\n",
    "    history_messages_key= 'history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0a295f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_a] 질문: 안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?\n",
      "[user_a] 챗봇: 안녕하세요, 홍길동님! 저는 여러분의 질문에 답변하고 도움을 드리기 위해 만들어진 챗봇입니다. 어떤 궁금한 점이나 도움이 필요하신 부분이 있으신가요?\n",
      "\n",
      "[user_b] 질문: 안녕하세요, 저는 이순신입니다. 당신은 어떤 일을 하시나요?\n",
      "[user_b] 챗봇: 안녕하세요, 이순신님! 저는 여러분의 질문에 답변하고, 다양한 정보와 도움을 제공하는 챗봇입니다. 궁금한 점이나 도움이 필요한 부분이 있다면 언제든지 말씀해 주세요!\n",
      "\n",
      "[user_a] 질문: 저는 프로그래밍을 배우고 있습니다. 당신은 어떤 일을 하시나요?\n",
      "[user_a] 챗봇: 프로그래밍을 배우고 계시다니 멋지네요! 저는 여러분의 질문에 답변하고, 정보 제공, 문제 해결, 그리고 다양한 주제에 대한 상담을 하는 역할을 하고 있습니다. 프로그래밍에 관련된 질문이나 도움이 필요하시면 언제든지 말씀해 주세요! 어떤 언어를 배우고 계신가요?\n",
      "\n",
      "[user_b] 질문: 저는 역사에 관심이 많습니다. 당신은 어떤 분야에 관심이 있나요?\n",
      "[user_b] 챗봇: 역사에 관심이 많으시다니 정말 멋지네요! 저는 특정한 관심 분야가 없지만, 다양한 주제에 대한 정보를 제공할 수 있습니다. 역사, 과학, 기술, 문화, 예술 등 여러 분야에 대해 이야기할 수 있으니, 궁금한 점이나 더 알고 싶은 주제가 있다면 말씀해 주세요!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두개의 세션을 번갈아가면서 대화 RunnableWithMessageHistory 가 각 세션에 맞는 대화 기록을 관리합니다\n",
    "sessions = ['user_a','user_b']\n",
    "questions = [\n",
    "    '안녕하세요, 저는 홍길동입니다. 당신은 누구신가요?', #user_a 첫번째 질문\n",
    "    '안녕하세요, 저는 이순신입니다. 당신은 어떤 일을 하시나요?', #user_b 첫 번째 질문\n",
    "    '저는 프로그래밍을 배우고 있습니다. 당신은 어떤 일을 하시나요?', #user_a 두 번째 질문\n",
    "    '저는 역사에 관심이 많습니다. 당신은 어떤 분야에 관심이 있나요?' #user_b 두 번째 질문\n",
    "]\n",
    "for i,question in enumerate(questions):\n",
    "    session_id = sessions[i%2] # 세션 ID를 번갈아가며 사용 \n",
    "    result = chatbot.invoke({'input':question}, config = {'configurable': {'session_id':session_id}})\n",
    "    print(f'[{session_id}] 질문: {question}')\n",
    "    print(f'[{session_id}] 챗봇: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e58a4757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user_c] 질문: 저는 철수예요, 반갑습니다.\n",
      "[user_c] 챗봇: 안녕하세요, 철수님! 반갑습니다. 어떻게 도와드릴까요? 궁금한 점이나 이야기하고 싶은 것이 있다면 말씀해 주세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chatbot.invoke({'input':\"저는 철수예요, 반갑습니다\"}, config={'configurable' : {'session_id' : 'user_c'}})\n",
    "print(f'[user_c] 질문: 저는 철수예요, 반갑습니다.')\n",
    "print(f'[user_c] 챗봇: {result}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659ffc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'철수님이라고 하셨습니다! 맞나요? 더 궁금한 점이나 이야기하고 싶은 것이 있다면 언제든지 말씀해 주세요.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chatbot.invoke({'input' : '저는 누구라고요?'}, config = {'configurable': {'session_id' : 'user_c'}})\n",
    "result\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c95a3",
   "metadata": {},
   "source": [
    "요약 메모리 구현(대화내용 자동 요약)\n",
    "```\n",
    "긴 대화내용을 모두 프롬프트에 기록하는 것은 비 효율적 -> 프롬프트에 길이 제한에 걸릴 가능성이 있음\n",
    "Conversation Summary Memory\n",
    "0.3x 버전에서는 직접 요약용 체인을 만들어서 ChatMessageHistory에 적용\n",
    "```\n",
    "어떻게 요약?\n",
    "```\n",
    "- 일정길이 이상으로 대화가 누적되면, 과거 대화를 요약해서 핵심내용만 남김\n",
    "- 요약결과를 메모리에 시스템 메시지 등으로 저장 -> 메모리 절약\n",
    "- 새로운 사용자 입력 시 요약된 맥락 + 최근 몇 메시지만 참고해서 llm 전달\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85bf8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약용 프롬프트 템플릿\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system','당신은 대화 요약 전문가입니다. 대화의 주요 내용을 간결하게 요약해 주세요'),\n",
    "    ('human','{conversation}')   # 잔체 대화 내용을 하나의 문자열로 전달\n",
    "])\n",
    "# LCEL  \n",
    "summary_chain = summary_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ecb739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약전 user_d의 메모리 메세지 개수: 10\n",
      "Human: 안녕, 오늘 우리 뭐하려고 했지?\n",
      "AI: 안녕하세요! 오늘 어떤 이야기를 나누고 싶으신가요? 궁금한 점이나 하고 싶은 주제가 있다면 말씀해 주세요. 함께 이야기해보아요!\n",
      "Human: 아 맞다 내일 회의자료 준비해야지, 회의는 몇시지?\n",
      "AI: 회의 시간이 정확히 몇 시인지 기억이 나지 않으신가요? 회의 일정은 보통 이메일이나 캘린더에 기록되어 있을 텐데, 확인해보시면 좋을 것 같아요. 만약 회의 준비에 도움이 필요하시다면 어떤 자료를 준비해야 하는지 말씀해 주시면 도와드릴 수 있습니다!\n",
      "Human: 그 회의에 누가 참석하는지 기억나니?\n",
      "AI: 회의에 참석하는 사람들을 기억하는 것은 중요하지만, 제가 그 정보를 알 수는 없어요. 보통 회의 초대장이나 이메일에 참석자 목록이 포함되어 있을 텐데, 그걸 확인해보시면 좋을 것 같아요. 참석자 목록을 알고 계신다면, 그들과의 논의 주제나 역할에 대해 이야기해드릴 수 있습니다! 도움이 필요하시면 말씀해 주세요.\n",
      "Human: 단위 프로젝트 진행 상황도 공유해야 할까?\n",
      "AI: 네, 단위 프로젝트 진행 상황을 공유하는 것은 좋은 아이디어입니다. 회의에서 프로젝트의 현재 상태, 진행 중인 작업, 완료된 작업, 그리고 앞으로의 계획 등을 공유하면 참석자들이 프로젝트에 대한 이해를 높이고, 필요한 피드백이나 지원을 받을 수 있습니다. \n",
      "\n",
      "또한, 진행 상황을 공유함으로써 팀원 간의 협업을 촉진하고, 문제를 조기에 발견하여 해결할 수 있는 기회를 제공할 수 있습니다. 어떤 내용을 포함할지 고민 중이라면, 구체적인 진행 상황이나 이슈, 다음 단계 등을 정리해보세요. 도움이 필요하시면 언제든지 말씀해 주세요!\n",
      "Human: 최근에 이야기 했던 새로운 기능에 대한 업데이트는 있어?\n",
      "AI: 새로운 기능에 대한 업데이트는 프로젝트의 진행 상황에 따라 다를 수 있습니다. 만약 그 기능에 대한 구체적인 내용이나 개발 상황을 알고 계신다면, 그 정보를 바탕으로 업데이트를 준비하시면 좋을 것 같습니다. \n",
      "\n",
      "업데이트를 공유할 때는 다음과 같은 내용을 포함하면 유용할 수 있습니다:\n",
      "\n",
      "1. **기능 설명**: 새로운 기능이 무엇인지 간단히 설명합니다.\n",
      "2. **진행 상황**: 현재 개발이 어느 단계에 있는지, 완료된 부분과 진행 중인 부분을 나누어 설명합니다.\n",
      "3. **예상 일정**: 기능이 언제 완료될 것으로 예상되는지, 배포 일정은 어떻게 되는지 공유합니다.\n",
      "4. **이슈 및 해결 방안**: 개발 중 발생한 문제나 이슈가 있다면, 그에 대한 해결 방안도 함께 공유합니다.\n",
      "\n",
      "이런 정보를 준비하면 회의에서 유익한 논의가 이루어질 수 있을 것입니다. 추가적인 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# user_d 세션에 대화내용을 기록 간 대화 생성\n",
    "long_queries = [\n",
    "    '안녕, 오늘 우리 뭐하려고 했지?',\n",
    "    '아 맞다 내일 회의자료 준비해야지, 회의는 몇시지?',\n",
    "    '그 회의에 누가 참석하는지 기억나니?',\n",
    "    '단위 프로젝트 진행 상황도 공유해야 할까?',\n",
    "    '최근에 이야기 했던 새로운 기능에 대한 업데이트는 있어?'\n",
    "]\n",
    "session_id = 'user_d'\n",
    "for q in long_queries:\n",
    "    answer = chatbot.invoke({'input':q}, config={'configurable' : {'session_id' : session_id}})\n",
    "\n",
    "print(f'요약전 user_d의 메모리 메세지 개수: {len(store[session_id].messages)}')\n",
    "print(store[session_id]) #요약하기전 대화 내용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8b8ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 요약 내용 ==\n",
      "대화 요약: \n",
      "사용자는 내일 회의 자료를 준비해야 한다고 언급하며 회의 시간과 참석자를 확인하려고 한다. AI는 회의 일정과 참석자 목록을 이메일이나 캘린더에서 확인할 것을 제안하고, 단위 프로젝트 진행 상황을 회의에서 공유하는 것이 좋다고 조언한다. AI는 진행 상황 공유가 팀 협업과 문제 해결에 도움이 될 것이라고 강조하며, 필요한 경우 추가 도움을 제공할 준비가 되어 있다고 말한다.\n"
     ]
    }
   ],
   "source": [
    "# 전체 대화 내용을 요약하고 마지막 사용자 질문-답변 쌍만 원본 유지\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "# 요약 대상 대화 내용 추출(마지막 QA 쌍 제외한 이전 내용)\n",
    "message = store[session_id].messages\n",
    "\n",
    "# 1번 주고받은 대화 이후에 또 했다는 것 -> 마지막을 빼야함\n",
    "if len(message) > 2 :\n",
    "    original_dialog = '\\n'.join([f'{msg.type.upper()} : {msg.content}' for msg in message[ : -2]])\n",
    "else : \n",
    "    original_dialog = '\\n'.join([f'{msg.type.upper()} : {msg.content}' for msg in message])\n",
    "\n",
    "# llm으로 요약 생성\n",
    "summary_text = summary_chain.invoke({'conversation' : original_dialog})\n",
    "print(\"== 요약 내용 ==\")\n",
    "print(summary_text)\n",
    "# 기존 메모리를 요약으로 교체 : 이전 내용 요약본 + 최근 QA 유지\n",
    "new_history = InMemoryChatMessageHistory()\n",
    "new_history.messages.append(SystemMessage(content = f'요약: {summary_text}'))\n",
    "\n",
    "# 최근 대화의 마지막 QA쌍 복원\n",
    "if len(message) >= 2 :\n",
    "    last_user_msg = message[-2]\n",
    "    last_ai_msg = message[-1]\n",
    "    # 휴먼 메시지인지 검사\n",
    "    if isinstance(last_user_msg, HumanMessage) :\n",
    "        new_history.add_user_message(last_user_msg.content)\n",
    "    else :\n",
    "        new_history.messages.append(last_user_msg)\n",
    "    if isinstance(last_ai_msg, AIMessage) :\n",
    "        new_history.add_ai_message(last_ai_msg.content)\n",
    "    else :\n",
    "        new_history.messages.append(last_ai_msg)\n",
    "# 메모리 교체\n",
    "store[session_id] = new_history\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2021cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
